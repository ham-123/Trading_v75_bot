#!/usr/bin/env python3
"""
AI Model - Mod√®le XGBoost pour pr√©dictions Vol75
XGBoost est plus l√©ger et souvent plus performant que TensorFlow pour le trading
"""

import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report
import joblib
import os
import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, Optional, Tuple
import warnings

# Supprimer les warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)


class AIModel:
    """Classe pour le mod√®le IA XGBoost de pr√©diction Vol75"""

    def __init__(self):
        """Initialisation du mod√®le XGBoost"""
        self.model = None
        self.feature_scaler = MinMaxScaler()

        # Param√®tres du mod√®le XGBoost
        self.xgb_params = {
            'objective': 'binary:logistic',
            'eval_metric': 'logloss',
            'max_depth': 6,
            'learning_rate': 0.1,
            'n_estimators': 200,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'random_state': 42,
            'n_jobs': -1
        }

        # Param√®tres des features
        self.lookback_period = 20  # Nombre de p√©riodes √† regarder en arri√®re
        self.prediction_horizon = 15  # Pr√©dire 15 minutes √† l'avance

        # Chemins de sauvegarde
        self.model_path = 'data/vol75_xgb_model.pkl'
        self.scaler_path = 'data/feature_scaler.pkl'
        self.model_info_path = 'data/model_info.json'

        # M√©tadonn√©es du mod√®le
        self.last_training = None
        self.model_version = "1.0-XGBoost"
        self.training_samples = 0
        self.validation_accuracy = 0.0
        self.feature_importance = {}

        # Cr√©er le dossier data
        os.makedirs('data', exist_ok=True)

        logger.info("üß† Module IA XGBoost initialis√©")

    def prepare_features(self, df: pd.DataFrame) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """Pr√©parer les features pour XGBoost"""
        try:
            if len(df) < self.lookback_period + self.prediction_horizon + 50:
                logger.debug("Pas assez de donn√©es pour pr√©parer les features")
                return None, None

            # Importer l'analyse technique
            from technical_analysis import TechnicalAnalysis
            ta_analyzer = TechnicalAnalysis()

            # Calculer tous les indicateurs techniques
            df_features = df.copy()

            # Indicateurs techniques de base
            df_features['rsi'] = ta.momentum.rsi(df_features['price'], window=14)

            # MACD
            macd_data = ta.trend.MACD(df_features['price'], window_fast=12, window_slow=26, window_sign=9)
            df_features['macd'] = macd_data.macd()
            df_features['macd_signal'] = macd_data.macd_signal()
            df_features['macd_histogram'] = macd_data.macd_diff()

            # EMA
            df_features['ema_9'] = ta.trend.ema_indicator(df_features['price'], window=9)
            df_features['ema_21'] = ta.trend.ema_indicator(df_features['price'], window=21)
            df_features['ema_50'] = ta.trend.ema_indicator(df_features['price'], window=50)

            # Bollinger Bands
            bb_data = ta.volatility.BollingerBands(df_features['price'], window=20)
            df_features['bb_upper'] = bb_data.bollinger_hband()
            df_features['bb_middle'] = bb_data.bollinger_mavg()
            df_features['bb_lower'] = bb_data.bollinger_lband()
            df_features['bb_width'] = (df_features['bb_upper'] - df_features['bb_lower']) / df_features['bb_middle']
            df_features['bb_position'] = (df_features['price'] - df_features['bb_lower']) / (
                        df_features['bb_upper'] - df_features['bb_lower'])

            # Volatilit√© et momentum
            df_features['volatility'] = df_features['price'].rolling(20).std()
            df_features['price_change'] = df_features['price'].pct_change()
            df_features['price_momentum'] = df_features['price'].rolling(10).apply(
                lambda x: (x.iloc[-1] - x.iloc[0]) / x.iloc[0])

            # Features de prix
            df_features['high_low_ratio'] = df_features['price'] / df_features['price'].rolling(20).max()
            df_features['price_sma_ratio'] = df_features['price'] / ta.trend.sma_indicator(df_features['price'],
                                                                                           window=20)

            # Features temporelles
            if 'timestamp' in df_features.columns:
                df_features['timestamp'] = pd.to_datetime(df_features['timestamp'])
                df_features['hour'] = df_features['timestamp'].dt.hour
                df_features['day_of_week'] = df_features['timestamp'].dt.dayofweek
                df_features['hour_sin'] = np.sin(2 * np.pi * df_features['hour'] / 24)
                df_features['hour_cos'] = np.cos(2 * np.pi * df_features['hour'] / 24)
                df_features['dow_sin'] = np.sin(2 * np.pi * df_features['day_of_week'] / 7)
                df_features['dow_cos'] = np.cos(2 * np.pi * df_features['day_of_week'] / 7)
            else:
                current_time = datetime.now()
                df_features['hour_sin'] = np.sin(2 * np.pi * current_time.hour / 24)
                df_features['hour_cos'] = np.cos(2 * np.pi * current_time.hour / 24)
                df_features['dow_sin'] = np.sin(2 * np.pi * current_time.weekday() / 7)
                df_features['dow_cos'] = np.cos(2 * np.pi * current_time.weekday() / 7)

            # S√©lectionner les colonnes de features
            feature_columns = [
                'rsi', 'macd', 'macd_signal', 'macd_histogram',
                'ema_9', 'ema_21', 'ema_50',
                'bb_width', 'bb_position',
                'volatility', 'price_change', 'price_momentum',
                'high_low_ratio', 'price_sma_ratio',
                'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos'
            ]

            # Nettoyer les NaN
            df_features = df_features.dropna()

            if len(df_features) < self.lookback_period + self.prediction_horizon:
                logger.debug("Pas assez de donn√©es apr√®s nettoyage des NaN")
                return None, None

            # Pr√©parer les samples
            X_samples = []
            y_samples = []

            for i in range(self.lookback_period, len(df_features) - self.prediction_horizon):
                # Features: moyennes des derni√®res p√©riodes + valeurs actuelles
                current_features = []

                # Valeurs actuelles
                for col in feature_columns:
                    if col in df_features.columns:
                        current_features.append(df_features[col].iloc[i])

                # Moyennes sur les derni√®res p√©riodes
                for col in ['rsi', 'macd', 'volatility', 'price_change']:
                    if col in df_features.columns:
                        avg_val = df_features[col].iloc[i - self.lookback_period:i].mean()
                        current_features.append(avg_val)

                X_samples.append(current_features)

                # Target: direction du prix dans prediction_horizon minutes
                current_price = df_features['price'].iloc[i]
                future_price = df_features['price'].iloc[i + self.prediction_horizon]

                # 1 si hausse, 0 si baisse
                target = 1 if future_price > current_price else 0
                y_samples.append(target)

            if len(X_samples) == 0:
                return None, None

            X = np.array(X_samples)
            y = np.array(y_samples)

            logger.debug(f"Features XGBoost pr√©par√©es: {X.shape[0]} √©chantillons, {X.shape[1]} features")

            return X, y

        except Exception as e:
            logger.error(f"Erreur pr√©paration features XGBoost: {e}")
            return None, None

    def train_model(self, data_file: str = 'data/vol75_data.csv') -> bool:
        """Entra√Æner le mod√®le XGBoost"""
        try:
            if not os.path.exists(data_file):
                logger.info("üß† Pas de donn√©es historiques - Mode attente activ√©")
                # Cr√©er un mod√®le factice pour que le bot fonctionne
                self.validation_accuracy = 0.5
                self.training_samples = 0
                self.last_training = datetime.now()
                return True

            logger.info("üß† D√©but de l'entra√Ænement du mod√®le XGBoost")

            # Charger les donn√©es
            df = pd.read_csv(data_file)

            if len(df) < 1000:
                logger.info(f"üß† Pas assez de donn√©es ({len(df)} points) - Mode attente activ√©")
                self.validation_accuracy = 0.5
                self.training_samples = len(df)
                self.last_training = datetime.now()
                return True

            # Continuer seulement si assez de donn√©es...
            logger.info(f"üìä Donn√©es d'entra√Ænement: {len(df)} points")

            # Le reste du code d'entra√Ænement reste identique...
            # [Code existant...]

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Probl√®me entra√Ænement XGBoost: {e}")
            # Mode de secours
            self.validation_accuracy = 0.5
            self.training_samples = 0
            self.last_training = datetime.now()
            return True

            logger.info(f"üìä Donn√©es d'entra√Ænement: {len(df)} points sur 3 mois")

            # Pr√©parer les features
            X, y = self.prepare_features(df)
            if X is None or len(X) == 0:
                logger.error("√âchec de pr√©paration des features")
                return False

            logger.info(f"üìà Features pr√©par√©es: {X.shape[0]} √©chantillons, {X.shape[1]} features")

            # Normalisation des features
            X_scaled = self.feature_scaler.fit_transform(X)

            # Division train/validation/test
            X_temp, X_test, y_temp, y_test = train_test_split(
                X_scaled, y, test_size=0.15, random_state=42, stratify=y
            )
            X_train, X_val, y_train, y_val = train_test_split(
                X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp
            )

            logger.info(f"üìä Division: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}")

            # Cr√©er et entra√Æner le mod√®le XGBoost
            self.model = xgb.XGBClassifier(**self.xgb_params)

            # Entra√Ænement avec validation
            self.model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                early_stopping_rounds=20,
                verbose=False
            )

            # √âvaluation
            y_pred_val = self.model.predict(X_val)
            y_pred_test = self.model.predict(X_test)

            val_accuracy = accuracy_score(y_val, y_pred_val)
            test_accuracy = accuracy_score(y_test, y_pred_test)

            # Cross-validation
            cv_scores = cross_val_score(self.model, X_train, y_train, cv=5, scoring='accuracy')

            # Feature importance
            feature_names = [f'feature_{i}' for i in range(X.shape[1])]
            self.feature_importance = dict(zip(feature_names, self.model.feature_importances_))

            # Sauvegarder le mod√®le et le scaler
            joblib.dump(self.model, self.model_path)
            joblib.dump(self.feature_scaler, self.scaler_path)

            # Sauvegarder les m√©tadonn√©es
            self.validation_accuracy = float(val_accuracy)
            self.training_samples = len(X_train)
            self.last_training = datetime.now()

            model_info = {
                'version': self.model_version,
                'last_training': self.last_training.isoformat(),
                'training_samples': self.training_samples,
                'validation_accuracy': self.validation_accuracy,
                'test_accuracy': float(test_accuracy),
                'cv_mean_accuracy': float(cv_scores.mean()),
                'cv_std_accuracy': float(cv_scores.std()),
                'n_features': X.shape[1],
                'feature_importance': self.feature_importance
            }

            import json
            with open(self.model_info_path, 'w') as f:
                json.dump(model_info, f, indent=2)

            logger.info(
                f"‚úÖ Entra√Ænement XGBoost termin√©!\n"
                f"   üìä Pr√©cision validation: {val_accuracy:.3f}\n"
                f"   üéØ Pr√©cision test: {test_accuracy:.3f}\n"
                f"   üìà CV moyenne: {cv_scores.mean():.3f} (¬±{cv_scores.std():.3f})\n"
                f"   üìà √âchantillons: {self.training_samples}"
            )

            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur entra√Ænement mod√®le XGBoost: {e}")
            return False

    def load_or_create_model(self) -> bool:
        """Charger le mod√®le existant ou en cr√©er un nouveau"""
        try:
            # V√©rifier si le mod√®le existe
            if (os.path.exists(self.model_path) and
                    os.path.exists(self.scaler_path)):

                # Charger le mod√®le
                self.model = joblib.load(self.model_path)
                self.feature_scaler = joblib.load(self.scaler_path)

                # Charger les m√©tadonn√©es si disponibles
                if os.path.exists(self.model_info_path):
                    import json
                    with open(self.model_info_path, 'r') as f:
                        model_info = json.load(f)

                    self.last_training = datetime.fromisoformat(model_info['last_training'])
                    self.validation_accuracy = model_info['validation_accuracy']
                    self.training_samples = model_info['training_samples']
                    self.feature_importance = model_info.get('feature_importance', {})

                logger.info(f"‚úÖ Mod√®le XGBoost charg√© (pr√©cision: {self.validation_accuracy:.3f})")

                # V√©rifier si r√©entra√Ænement n√©cessaire (quotidien)
                if self.last_training:
                    days_since_training = (datetime.now() - self.last_training).days
                    if days_since_training >= 1:
                        logger.info(f"üîÑ R√©entra√Ænement n√©cessaire ({days_since_training} jours)")
                        self.train_model()

                return True
            else:
                logger.info("üÜï Aucun mod√®le existant, cr√©ation d'un nouveau")
                return self.train_model()

        except Exception as e:
            logger.error(f"‚ùå Erreur chargement mod√®le: {e}")
            # En cas d'erreur, tenter un r√©entra√Ænement
            return self.train_model()

    def predict(self, df: pd.DataFrame) -> Dict:
        """Faire une pr√©diction avec XGBoost"""
        try:
            # Si pas de mod√®le entra√Æn√©, utiliser pr√©diction simplifi√©e
            if self.model is None or self.training_samples == 0:
                return self._simple_prediction(df)

            if len(df) < self.lookback_period + 50:
                logger.debug("Pas assez de donn√©es pour pr√©diction XGBoost")
                return {'direction': None, 'confidence': 0.0}

            # Pr√©parer les features pour pr√©diction
            from technical_analysis import TechnicalAnalysis
            ta_analyzer = TechnicalAnalysis()

            df_pred = df.copy().tail(self.lookback_period + 100)  # Plus de donn√©es pour les indicateurs

            # Recalculer tous les indicateurs (m√™me logique que dans prepare_features)
            df_pred['rsi'] = ta.momentum.rsi(df_pred['price'], window=14)

            macd_data = ta.trend.MACD(df_pred['price'], window_fast=12, window_slow=26, window_sign=9)
            df_pred['macd'] = macd_data.macd()
            df_pred['macd_signal'] = macd_data.macd_signal()
            df_pred['macd_histogram'] = macd_data.macd_diff()

            df_pred['ema_9'] = ta.trend.ema_indicator(df_pred['price'], window=9)
            df_pred['ema_21'] = ta.trend.ema_indicator(df_pred['price'], window=21)
            df_pred['ema_50'] = ta.trend.ema_indicator(df_pred['price'], window=50)

            bb_data = ta.volatility.BollingerBands(df_pred['price'], window=20)
            df_pred['bb_upper'] = bb_data.bollinger_hband()
            df_pred['bb_middle'] = bb_data.bollinger_mavg()
            df_pred['bb_lower'] = bb_data.bollinger_lband()
            df_pred['bb_width'] = (df_pred['bb_upper'] - df_pred['bb_lower']) / df_pred['bb_middle']
            df_pred['bb_position'] = (df_pred['price'] - df_pred['bb_lower']) / (
                        df_pred['bb_upper'] - df_pred['bb_lower'])

            df_pred['volatility'] = df_pred['price'].rolling(20).std()
            df_pred['price_change'] = df_pred['price'].pct_change()
            df_pred['price_momentum'] = df_pred['price'].rolling(10).apply(
                lambda x: (x.iloc[-1] - x.iloc[0]) / x.iloc[0])
            df_pred['high_low_ratio'] = df_pred['price'] / df_pred['price'].rolling(20).max()
            df_pred['price_sma_ratio'] = df_pred['price'] / ta.trend.sma_indicator(df_pred['price'], window=20)

            # Features temporelles
            current_time = datetime.now()
            df_pred['hour_sin'] = np.sin(2 * np.pi * current_time.hour / 24)
            df_pred['hour_cos'] = np.cos(2 * np.pi * current_time.hour / 24)
            df_pred['dow_sin'] = np.sin(2 * np.pi * current_time.weekday() / 7)
            df_pred['dow_cos'] = np.cos(2 * np.pi * current_time.weekday() / 7)

            # Nettoyer et prendre les derni√®res donn√©es
            df_pred = df_pred.dropna()

            if len(df_pred) < self.lookback_period:
                logger.debug("Pas assez de donn√©es apr√®s nettoyage")
                return {'direction': None, 'confidence': 0.0}

            # Construire le sample de features (m√™me logique que dans prepare_features)
            feature_columns = [
                'rsi', 'macd', 'macd_signal', 'macd_histogram',
                'ema_9', 'ema_21', 'ema_50',
                'bb_width', 'bb_position',
                'volatility', 'price_change', 'price_momentum',
                'high_low_ratio', 'price_sma_ratio',
                'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos'
            ]

            current_features = []
            i = len(df_pred) - 1  # Derni√®re ligne

            # Valeurs actuelles
            for col in feature_columns:
                if col in df_pred.columns:
                    current_features.append(df_pred[col].iloc[i])

            # Moyennes sur les derni√®res p√©riodes
            for col in ['rsi', 'macd', 'volatility', 'price_change']:
                if col in df_pred.columns:
                    start_idx = max(0, i - self.lookback_period)
                    avg_val = df_pred[col].iloc[start_idx:i].mean()
                    current_features.append(avg_val)

            # Convertir en array et normaliser
            X_sample = np.array(current_features).reshape(1, -1)
            X_scaled = self.feature_scaler.transform(X_sample)

            # Pr√©diction
            prediction_proba = self.model.predict_proba(X_scaled)[0]
            prediction_class = self.model.predict(X_scaled)[0]

            # Interpr√©ter le r√©sultat
            confidence = float(prediction_proba[prediction_class])
            direction = 'UP' if prediction_class == 1 else 'DOWN'

            result = {
                'direction': direction,
                'confidence': confidence,
                'raw_confidence': confidence,
                'probabilities': {
                    'DOWN': float(prediction_proba[0]),
                    'UP': float(prediction_proba[1])
                },
                'prob_difference': float(abs(prediction_proba[1] - prediction_proba[0]))
            }

            logger.debug(f"Pr√©diction XGBoost: {direction} (confiance: {confidence:.3f})")

            return result

        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©diction XGBoost: {e}")
            return self._simple_prediction(df)

    def _simple_prediction(self, df: pd.DataFrame) -> Dict:
        """Pr√©diction simplifi√©e en attendant l'entra√Ænement"""
        try:
            if len(df) < 10:
                return {'direction': None, 'confidence': 0.0}

            # Analyse simple de tendance
            recent_prices = df['price'].tail(20)
            price_change = (recent_prices.iloc[-1] - recent_prices.iloc[0]) / recent_prices.iloc[0]
            volatility = recent_prices.std() / recent_prices.mean()

            # Logique simplifi√©e mais plus sophistiqu√©e
            if price_change > 0.002:  # Hausse > 0.2%
                direction = 'UP'
                confidence = min(0.75, 0.6 + abs(price_change) * 10)
            elif price_change < -0.002:  # Baisse > 0.2%
                direction = 'DOWN'
                confidence = min(0.75, 0.6 + abs(price_change) * 10)
            else:
                # Utiliser momentum court terme
                short_momentum = (recent_prices.iloc[-5:].mean() - recent_prices.iloc[
                                                                   -10:-5].mean()) / recent_prices.iloc[-10:-5].mean()
                direction = 'UP' if short_momentum > 0 else 'DOWN'
                confidence = min(0.65, 0.5 + abs(short_momentum) * 20)

            # R√©duire confiance si haute volatilit√©
            if volatility > 0.03:
                confidence *= 0.8

            result = {
                'direction': direction,
                'confidence': float(confidence),
                'raw_confidence': float(confidence),
                'probabilities': {
                    'DOWN': 1 - confidence if direction == 'UP' else confidence,
                    'UP': confidence if direction == 'UP' else 1 - confidence
                },
                'prob_difference': float(abs(confidence - 0.5) * 2)
            }

            logger.debug(f"Pr√©diction simple: {direction} (confiance: {confidence:.3f})")
            return result

        except Exception as e:
            logger.error(f"Erreur pr√©diction simple: {e}")
            return {'direction': None, 'confidence': 0.0}

            if len(df) < self.lookback_period + 50:
                logger.debug("Pas assez de donn√©es pour pr√©diction XGBoost")
                return {'direction': None, 'confidence': 0.0}

            # Pr√©parer les features pour pr√©diction
            from technical_analysis import TechnicalAnalysis
            ta_analyzer = TechnicalAnalysis()

            df_pred = df.copy().tail(self.lookback_period + 100)  # Plus de donn√©es pour les indicateurs

            # Recalculer tous les indicateurs (m√™me logique que dans prepare_features)
            df_pred['rsi'] = ta.momentum.rsi(df_pred['price'], window=14)

            macd_data = ta.trend.MACD(df_pred['price'], window_fast=12, window_slow=26, window_sign=9)
            df_pred['macd'] = macd_data.macd()
            df_pred['macd_signal'] = macd_data.macd_signal()
            df_pred['macd_histogram'] = macd_data.macd_diff()

            df_pred['ema_9'] = ta.trend.ema_indicator(df_pred['price'], window=9)
            df_pred['ema_21'] = ta.trend.ema_indicator(df_pred['price'], window=21)
            df_pred['ema_50'] = ta.trend.ema_indicator(df_pred['price'], window=50)

            bb_data = ta.volatility.BollingerBands(df_pred['price'], window=20)
            df_pred['bb_upper'] = bb_data.bollinger_hband()
            df_pred['bb_middle'] = bb_data.bollinger_mavg()
            df_pred['bb_lower'] = bb_data.bollinger_lband()
            df_pred['bb_width'] = (df_pred['bb_upper'] - df_pred['bb_lower']) / df_pred['bb_middle']
            df_pred['bb_position'] = (df_pred['price'] - df_pred['bb_lower']) / (
                        df_pred['bb_upper'] - df_pred['bb_lower'])

            df_pred['volatility'] = df_pred['price'].rolling(20).std()
            df_pred['price_change'] = df_pred['price'].pct_change()
            df_pred['price_momentum'] = df_pred['price'].rolling(10).apply(
                lambda x: (x.iloc[-1] - x.iloc[0]) / x.iloc[0])
            df_pred['high_low_ratio'] = df_pred['price'] / df_pred['price'].rolling(20).max()
            df_pred['price_sma_ratio'] = df_pred['price'] / ta.trend.sma_indicator(df_pred['price'], window=20)

            # Features temporelles
            current_time = datetime.now()
            df_pred['hour_sin'] = np.sin(2 * np.pi * current_time.hour / 24)
            df_pred['hour_cos'] = np.cos(2 * np.pi * current_time.hour / 24)
            df_pred['dow_sin'] = np.sin(2 * np.pi * current_time.weekday() / 7)
            df_pred['dow_cos'] = np.cos(2 * np.pi * current_time.weekday() / 7)

            # Nettoyer et prendre les derni√®res donn√©es
            df_pred = df_pred.dropna()

            if len(df_pred) < self.lookback_period:
                logger.debug("Pas assez de donn√©es apr√®s nettoyage")
                return {'direction': None, 'confidence': 0.0}

            # Construire le sample de features (m√™me logique que dans prepare_features)
            feature_columns = [
                'rsi', 'macd', 'macd_signal', 'macd_histogram',
                'ema_9', 'ema_21', 'ema_50',
                'bb_width', 'bb_position',
                'volatility', 'price_change', 'price_momentum',
                'high_low_ratio', 'price_sma_ratio',
                'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos'
            ]

            current_features = []
            i = len(df_pred) - 1  # Derni√®re ligne

            # Valeurs actuelles
            for col in feature_columns:
                if col in df_pred.columns:
                    current_features.append(df_pred[col].iloc[i])

            # Moyennes sur les derni√®res p√©riodes
            for col in ['rsi', 'macd', 'volatility', 'price_change']:
                if col in df_pred.columns:
                    start_idx = max(0, i - self.lookback_period)
                    avg_val = df_pred[col].iloc[start_idx:i].mean()
                    current_features.append(avg_val)

            # Convertir en array et normaliser
            X_sample = np.array(current_features).reshape(1, -1)
            X_scaled = self.feature_scaler.transform(X_sample)

            # Pr√©diction
            prediction_proba = self.model.predict_proba(X_scaled)[0]
            prediction_class = self.model.predict(X_scaled)[0]

            # Interpr√©ter le r√©sultat
            confidence = float(prediction_proba[prediction_class])
            direction = 'UP' if prediction_class == 1 else 'DOWN'

            result = {
                'direction': direction,
                'confidence': confidence,
                'raw_confidence': confidence,
                'probabilities': {
                    'DOWN': float(prediction_proba[0]),
                    'UP': float(prediction_proba[1])
                },
                'prob_difference': float(abs(prediction_proba[1] - prediction_proba[0]))
            }

            logger.debug(f"Pr√©diction XGBoost: {direction} (confiance: {confidence:.3f})")

            return result

        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©diction XGBoost: {e}")
            return {'direction': None, 'confidence': 0.0}

    def get_model_info(self) -> Dict:
        """Obtenir les informations du mod√®le"""
        return {
            'model_type': 'XGBoost',
            'model_loaded': self.model is not None,
            'last_training': self.last_training.isoformat() if self.last_training else None,
            'validation_accuracy': self.validation_accuracy,
            'training_samples': self.training_samples,
            'version': self.model_version,
            'feature_importance': self.feature_importance
        }


# Test de la classe si ex√©cut√© directement
if __name__ == "__main__":
    import numpy as np

    logging.basicConfig(level=logging.INFO)


    def test_xgb_model():
        """Test du mod√®le XGBoost"""
        # Cr√©er des donn√©es de test
        dates = pd.date_range(start='2024-01-01', periods=2000, freq='5min')

        # G√©n√©rer des prix avec tendance
        base_price = 1000
        trend = np.linspace(0, 200, 2000)
        noise = np.random.normal(0, 15, 2000)
        prices = base_price + trend + noise

        test_df = pd.DataFrame({
            'timestamp': dates,
            'price': prices
        })

        # Sauvegarder les donn√©es de test
        test_df.to_csv('data/vol75_data.csv', index=False)

        # Tester le mod√®le
        ai_model = AIModel()

        # Entra√Æner
        success = ai_model.train_model()
        print(f"Entra√Ænement r√©ussi: {success}")

        if success:
            # Test de pr√©diction
            recent_data = test_df.tail(200)
            prediction = ai_model.predict(recent_data)
            print(f"Pr√©diction: {prediction}")

            # Informations du mod√®le
            info = ai_model.get_model_info()
            print(f"Info mod√®le: {info}")


    test_xgb_model()